{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBottt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4coa7SfjLkTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import gensim\n",
        "import numpy as np\n",
        "import nltk\n",
        "from gensim import corpora, models, similarities\n",
        "import pickle\n",
        "os.chdir(\"drive/My Drive/chatbot\")\n",
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqX6IA8YOMCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ec20e88c-0403-4923-d1aa-42007a046a81"
      },
      "source": [
        "import gensim.models.keyedvectors as word2vec\n",
        "model = word2vec.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7EjlJv7PcmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"conversation.json\") as file:\n",
        "  data = json.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uj8sDW1Q6gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpo = data[\"conversations\"]\n",
        "inp = []\n",
        "out = []\n",
        "\n",
        "for i in range(len(corpo)):\n",
        "  for j in range(len(corpo[i]) - 1):\n",
        "    inp.append(corpo[i][j])\n",
        "    out.append(corpo[i][j+1])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClnJh8ZR7eP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "55615549-9ab0-4845-9b39-f911b0cfdda6"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\"Input\" : inp, \"Output\" : out})\n",
        "df.head()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good morning, how are you?</td>\n",
              "      <td>I am doing well, how about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am doing well, how about you?</td>\n",
              "      <td>I'm also good.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm also good.</td>\n",
              "      <td>That's good to hear.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That's good to hear.</td>\n",
              "      <td>Yes it is.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hello</td>\n",
              "      <td>Hi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             Input                           Output\n",
              "0       Good morning, how are you?  I am doing well, how about you?\n",
              "1  I am doing well, how about you?                   I'm also good.\n",
              "2                   I'm also good.             That's good to hear.\n",
              "3             That's good to hear.                       Yes it is.\n",
              "4                            Hello                               Hi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnMKkiP9UoHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "xtok = [tokenizer.tokenize(x.lower()) for x in inp]\n",
        "ytok = [tokenizer.tokenize(y.lower()) for y in out]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3XBw4CAVQLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xvecs = []\n",
        "for sen in xtok:\n",
        "  v = [model[w] for w in sen if w in model.vocab]\n",
        "  xvecs.append(v)\n",
        "\n",
        "yvecs = []\n",
        "for sen in ytok:\n",
        "  v = [model[w] for w in sen if w in model.vocab]\n",
        "  yvecs.append(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6uJkPDfWL6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eos = np.ones((300), dtype = np.float32)\n",
        "for tok_sent in xvecs:\n",
        "  if len(tok_sent) < 15:\n",
        "    for i in range(15 - len(tok_sent)):\n",
        "      tok_sent.append(eos)\n",
        "  else :\n",
        "    tok_sent[14:] = []\n",
        "    tok_sent.append(eos)\n",
        "\n",
        "for tok_sent in yvecs:\n",
        "  if len(tok_sent) < 15:\n",
        "    for i in range(15 - len(tok_sent)):\n",
        "      tok_sent.append(eos)\n",
        "  else :\n",
        "    tok_sent[14:] = []\n",
        "    tok_sent.append(eos)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJGUdvB3Z3Fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"data.pickle\", \"wb\" ) as f:\n",
        "  pickle.dump([xvecs, yvecs], f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3A78-e_n65s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pickle\n",
        "# with open(\"data.pickle\", \"rb\" ) as f:\n",
        "#   xvecs, yvecs = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3MoHaXTeG8L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9cc00a0-8b51-43bd-c025-ab692ac670ad"
      },
      "source": [
        "x_arr = np.array(xvecs, dtype = np.float64)\n",
        "y_arr = np.array(yvecs, dtype = np.float64)\n",
        "x_arr.shape\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 15, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHxkYdIjAK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Dropout , Lambda, Flatten, LSTM, Input, Embedding\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import  backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XCQYe3djFzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(x_arr, y_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-_3CGeMjuVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "fa7924b4-d9b5-4fd9-cc24-e4586586eafc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(output_dim=300,input_shape=xtrain.shape[1:],return_sequences=True, init='glorot_normal', inner_init='glorot_normal', activation='sigmoid'))\n",
        "model.add(LSTM(output_dim=300,input_shape=xtrain.shape[1:],return_sequences=True, init='glorot_normal', inner_init='glorot_normal', activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='cosine_proximity', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(15, 300), return_sequences=True, activation=\"sigmoid\", units=300, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"glorot_normal\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Xc2LQPlCnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5503d530-a9fe-4acb-b0bd-9b1013ae332f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 15, 300)           721200    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 15, 300)           721200    \n",
            "=================================================================\n",
            "Total params: 1,442,400\n",
            "Trainable params: 1,442,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMzEyxQwlHsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "model.fit(xtrain, ytrain, nb_epoch=1000, validation_data=(xtest, ytest), callbacks =[EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100), ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)])\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNcF5SLFrKTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import gensim\n",
        "import gensim.models.keyedvectors as word2vec\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/chatbot\")\n",
        "\n",
        "bot_model = load_model('model.h5')\n",
        "\n",
        "w2v = word2vec.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bFOdAcmtP0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "eos = np.ones((300), dtype = np.float32)\n",
        "x = input(\"Enter query\")\n",
        "x = tokenizer.tokenize(x)\n",
        "vec = [w2v[i] for i in x if i in w2v.vocab]\n",
        "\n",
        "if len(vec) < 15:\n",
        "  for i in range(15 - len(vec)):\n",
        "    vec.append(eos)\n",
        "else :\n",
        "  vec[14:] = []\n",
        "  vec.append(eos)\n",
        "vec = np.array([vec])\n",
        "pred = bot_model.predict(vec)\n",
        "\n",
        "word_list_out = [w2v.similar_by_vector(v)[0] for v in pred[0]]\n",
        "print(\" \".join(word_list_out))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}